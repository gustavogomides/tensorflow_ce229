{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import MINST data\n",
    "import tensorflow as tf\n",
    "from util import plot_data, get_mnist, print_predict_image\n",
    "import numpy as np\n",
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels: 60000\n",
      "Test labels: 10000\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, y_train_classes, x_test, y_test = get_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 10000\n",
    "batch_size = 256\n",
    "display_step = 10\n",
    "# Network Parameters\n",
    "n_input = 784  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "dropout = 0.2  # Dropout, probability to keep units\n",
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "# dropout (keep probability)\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(img, w, b):\n",
    "    return tf.nn.relu(tf.nn.bias_add\n",
    "                      (tf.nn.conv2d(img, w,\n",
    "                                    strides=[1, 1, 1, 1],\n",
    "                                    padding='SAME'), b))\n",
    "\n",
    "def max_pool(img, k):\n",
    "    return tf.nn.max_pool(img,\n",
    "                          ksize=[1, k, k, 1],\n",
    "                          strides=[1, k, k, 1],\n",
    "                          padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-5-4f519a56fb49>:31: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-5-4f519a56fb49>:36: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/tf_should_use.py:193: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "# Store layers weight & bias\n",
    "# 5x5 conv, 1 input, 32 outputs\n",
    "wc1 = tf.Variable(tf.random_normal([5, 5, 1, 32]))\n",
    "bc1 = tf.Variable(tf.random_normal([32]))\n",
    "# 5x5 conv, 32 inputs, 64 outputs\n",
    "wc2 = tf.Variable(tf.random_normal([5, 5, 32, 64]))\n",
    "bc2 = tf.Variable(tf.random_normal([64]))\n",
    "# fully connected, 7*7*64 inputs, 1024 outputs\n",
    "wd1 = tf.Variable(tf.random_normal([7*7*64, 1024]))\n",
    "# 1024 inputs, 10 outputs (class prediction)\n",
    "wout = tf.Variable(tf.random_normal([1024, n_classes]))\n",
    "bd1 = tf.Variable(tf.random_normal([1024]))\n",
    "\n",
    "bout = tf.Variable(tf.random_normal([n_classes]))\n",
    "# Construct model\n",
    "# _X = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "# Convolution Layer\n",
    "conv1 = conv2d(x, wc1, bc1)\n",
    "# Max Pooling (down-sampling)\n",
    "conv1 = max_pool(conv1, k=2)\n",
    "# Convolution Layer\n",
    "conv2 = conv2d(conv1, wc2, bc2)\n",
    "# Max Pooling (down-sampling)\n",
    "conv2 = max_pool(conv2, k=2)\n",
    "# Fully connected layer\n",
    "# Reshape conv2 output to fit dense layer input\n",
    "dense1 = tf.reshape(conv2, [-1, wd1.get_shape().as_list()[0]])\n",
    "# Relu activation\n",
    "dense1 = tf.nn.relu(tf.add(tf.matmul(dense1, wd1), bd1))\n",
    "# Apply Dropout\n",
    "dense1 = tf.nn.dropout(dense1, keep_prob)\n",
    "# Output, class prediction\n",
    "pred = tf.add(tf.matmul(dense1, wout), bout)\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=pred))\n",
    "optimizer =\\\n",
    "    tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(images, labels, batch_size):\n",
    "    \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "    _index_in_epoch = 0\n",
    "    start = _index_in_epoch\n",
    "    _index_in_epoch += batch_size\n",
    "    num_examples = images.shape[0]\n",
    "    _epochs_completed = 0\n",
    "    if _index_in_epoch > num_examples:\n",
    "        # Finished epoch\n",
    "        _epochs_completed += 1\n",
    "        # Shuffle the data\n",
    "        perm = np.arange(num_examples)\n",
    "        np.random.shuffle(perm)\n",
    "        images = images[perm]\n",
    "        labels = labels[perm]\n",
    "        # Start next epoch\n",
    "        start = 0\n",
    "        _index_in_epoch = batch_size\n",
    "        assert batch_size <= num_examples\n",
    "    end = _index_in_epoch\n",
    "    return images[start:end], labels[start:end]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2560, Minibatch Loss= 20725.785156, Training Accuracy= 0.42578\n",
      "Iter 5120, Minibatch Loss= 13027.311523, Training Accuracy= 0.63672\n",
      "Iter 7680, Minibatch Loss= 5838.890625, Training Accuracy= 0.75781\n",
      "Iter 10240, Minibatch Loss= 3372.833008, Training Accuracy= 0.84766\n",
      "Iter 12800, Minibatch Loss= 2724.508057, Training Accuracy= 0.87891\n",
      "Iter 15360, Minibatch Loss= 2561.396729, Training Accuracy= 0.88672\n",
      "Iter 17920, Minibatch Loss= 1947.501953, Training Accuracy= 0.91406\n",
      "Iter 20480, Minibatch Loss= 1515.615479, Training Accuracy= 0.92969\n",
      "Iter 23040, Minibatch Loss= 1118.739014, Training Accuracy= 0.94531\n",
      "Iter 25600, Minibatch Loss= 838.832092, Training Accuracy= 0.95312\n",
      "Iter 28160, Minibatch Loss= 758.288025, Training Accuracy= 0.96094\n",
      "Iter 30720, Minibatch Loss= 602.754761, Training Accuracy= 0.96484\n",
      "Iter 33280, Minibatch Loss= 432.504517, Training Accuracy= 0.97266\n",
      "Iter 35840, Minibatch Loss= 291.515076, Training Accuracy= 0.97266\n",
      "Iter 38400, Minibatch Loss= 202.433548, Training Accuracy= 0.98438\n",
      "Iter 40960, Minibatch Loss= 162.237274, Training Accuracy= 0.98828\n",
      "Iter 43520, Minibatch Loss= 129.653809, Training Accuracy= 0.99219\n",
      "Iter 46080, Minibatch Loss= 103.815681, Training Accuracy= 0.99219\n",
      "Iter 48640, Minibatch Loss= 65.554756, Training Accuracy= 0.99219\n",
      "Iter 51200, Minibatch Loss= 25.384079, Training Accuracy= 0.99219\n",
      "Iter 53760, Minibatch Loss= 21.321281, Training Accuracy= 0.99609\n",
      "Iter 56320, Minibatch Loss= 10.588676, Training Accuracy= 0.99609\n",
      "Iter 58880, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 61440, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 64000, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 66560, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 69120, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 71680, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 74240, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 76800, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 79360, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 81920, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 84480, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 87040, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 89600, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 92160, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 94720, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 97280, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 99840, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 102400, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 104960, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 107520, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 110080, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 112640, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 115200, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 117760, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 120320, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 122880, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 125440, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 128000, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 130560, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 133120, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 135680, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 138240, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 140800, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 143360, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 145920, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 148480, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 151040, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 153600, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 156160, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 158720, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 161280, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 163840, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 166400, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 168960, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 171520, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 174080, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 176640, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 179200, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 181760, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 184320, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 186880, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 189440, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 192000, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 194560, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 197120, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 199680, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 202240, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 204800, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 207360, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 209920, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 212480, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 215040, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 217600, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 220160, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 222720, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 225280, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 227840, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 230400, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 232960, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 235520, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 238080, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 240640, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 243200, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 245760, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 248320, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 250880, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 253440, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 256000, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 258560, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 261120, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 263680, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 266240, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 268800, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 271360, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 273920, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 276480, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 279040, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 281600, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 284160, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 286720, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 289280, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 291840, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 294400, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 296960, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 299520, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 302080, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 304640, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 307200, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 309760, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 312320, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 314880, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 317440, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 320000, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 322560, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 325120, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 327680, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 330240, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 332800, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 335360, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 337920, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 340480, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 343040, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 345600, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 348160, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 350720, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 353280, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 355840, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 358400, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 360960, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 363520, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 366080, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 368640, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 371200, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 373760, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 376320, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 378880, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 381440, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 384000, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 386560, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 389120, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 391680, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 394240, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 396800, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 399360, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 401920, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 404480, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 407040, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 409600, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 412160, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 414720, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 417280, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 419840, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 422400, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 424960, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 427520, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 430080, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 432640, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 435200, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 437760, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 440320, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 442880, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 445440, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 448000, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 450560, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 453120, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 455680, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 458240, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 460800, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 463360, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 465920, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 468480, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 471040, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 473600, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 476160, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 478720, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 481280, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 483840, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 486400, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 488960, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 491520, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 494080, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 496640, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 499200, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 501760, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 504320, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 506880, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 509440, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 512000, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-55bc2029dd6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         sess.run(optimizer, feed_dict={x: batch_xs,\n\u001b[1;32m     10\u001b[0m                                        \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                                        keep_prob: dropout})\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdisplay_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;31m# Calculate batch accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_xs, batch_ys = next_batch(x_train, y_train, batch_size)\n",
    "\n",
    "        # Fit training using batch data\n",
    "        sess.run(optimizer, feed_dict={x: batch_xs,\n",
    "                                       y: batch_ys,\n",
    "                                       keep_prob: dropout})\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch accuracy\n",
    "            acc = sess.run(accuracy, feed_dict={x: batch_xs,\n",
    "                                                y: batch_ys,\n",
    "                                                keep_prob: 1.})\n",
    "            # Calculate batch loss\n",
    "            loss = sess.run(cost, feed_dict={x: batch_xs,\n",
    "                                             y: batch_ys,\n",
    "                                             keep_prob: 1.})\n",
    "            print(\"Iter \" + str(step*batch_size) +\n",
    "                  \", Minibatch Loss= \" +\n",
    "                  \"{:.6f}\".format(loss) +\n",
    "                  \", Training Accuracy= \" +\n",
    "                  \"{:.5f}\".format(acc))\n",
    "        step += 1\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "    print(\"Testing Accuracy:\",\n",
    "          sess.run(accuracy,\n",
    "                   feed_dict={x: x_test,\n",
    "                              y: y_test,\n",
    "                              keep_prob: 1.}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
